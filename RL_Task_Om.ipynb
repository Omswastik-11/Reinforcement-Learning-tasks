{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d85ce86-f4cc-4fc7-a46f-266a819a46f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.0 (SDL 2.28.4, Python 3.8.19)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pygame\n",
    "import time\n",
    "from pettingzoo.utils import agent_selector\n",
    "from pettingzoo.utils.env import AECEnv\n",
    "from gym import spaces\n",
    "from pettingzoo.utils import wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e06fa4d6-c0c2-4a4a-87e3-ca60b7d54cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MazeXEnv(AECEnv):\n",
    "    metadata = {'render_modes':['human','ansi']}\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.maze = np.array([\n",
    "            [0,0,0,1,0,1,0,0,0,1,0,0,0,1,0,0,0,0,0,1],\n",
    "            [1,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,1,1,0,1],\n",
    "            [0,0,0,1,0,0,0,1,0,0,0,1,0,1,0,1,0,0,0,1],\n",
    "            [0,1,1,1,1,1,1,1,0,1,1,1,0,1,0,1,0,1,1,1],\n",
    "            [0,1,0,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1],\n",
    "            [0,1,0,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,0,1],\n",
    "            [0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1,0,0,0,1],\n",
    "            [1,1,1,1,0,1,1,1,0,1,0,1,0,0,0,0,0,1,0,1],\n",
    "            [0,0,0,0,0,0,0,1,0,1,0,1,0,1,1,1,0,1,0,1],\n",
    "            [0,1,1,1,0,1,1,1,0,0,0,1,0,0,0,1,0,1,1,1],\n",
    "            [0,1,0,1,0,0,0,0,0,1,0,1,0,1,0,1,0,0,0,1],\n",
    "            [0,1,0,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,1],\n",
    "            [0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,1],\n",
    "            [0,1,0,1,1,1,1,0,1,1,0,1,1,1,1,1,1,1,0,1],\n",
    "            [0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "        ])\n",
    "        self._cumulative_rewards = {'robber': 0, 'cop': 0}\n",
    "        self.start = (0, 0)\n",
    "        self.goal = (14,19)\n",
    "        self.checkpoints = [(14, 6), (10, 9), (13, 10), (10, 2)]\n",
    "        self.state = self.start\n",
    "        self.cop_state = (14, 0)\n",
    "       \n",
    "        self.agents = ['robber', 'cop']\n",
    "        self.agent_order = self.agents\n",
    "        self._agent_selector = agent_selector(self.agent_order)\n",
    "        self.agent_selection = self._agent_selector.next()\n",
    "       \n",
    "        self.observation_spaces = {agent: spaces.Box(low=0, high=max(self.maze.shape)-1, shape=(2,), dtype=np.int32) for agent in self.agents}\n",
    "        self.action_spaces = {agent: spaces.Discrete(4) for agent in self.agents}\n",
    "       \n",
    "        self.rewards = {agent: 0 for agent in self.agents}\n",
    "        self.dones = {agent: False for agent in self.agents}\n",
    "        self.infos = {agent: {} for agent in self.agents}\n",
    "\n",
    "        self.render_mode = 'human'  # Added render_mode attribute\n",
    "       \n",
    "        # Pygame setup\n",
    "        self.screen_width = 800\n",
    "        self.screen_height = 600\n",
    "        self.screen_size = (self.screen_width, self.screen_height)\n",
    "        self.cell_size = min(self.screen_width // self.maze.shape[1], self.screen_height // self.maze.shape[0])\n",
    "        pygame.init()\n",
    "        self.screen = pygame.display.set_mode(self.screen_size)\n",
    "        pygame.display.set_caption('MazeX')\n",
    "\n",
    "    def observe(self, agent):\n",
    "        if agent == 'robber':\n",
    "            return np.array(self.state)\n",
    "        elif agent == 'cop':\n",
    "            return np.array(self.cop_state)\n",
    "\n",
    "    def reset(self, seed=None, options=None):  # Modified reset to accept seed and options\n",
    "        self.state = self.start\n",
    "        self.cop_state = (14, 0)\n",
    "        self.rewards = {agent: 0 for agent in self.agents}\n",
    "        self.dones = {agent: False for agent in self.agents}\n",
    "        self.infos = {agent: {} for agent in self.agents}\n",
    "        self.agent_selection = self._agent_selector.reset()\n",
    "        self._cumulative_rewards = {'robber': 0, 'cop': 0}\n",
    "   \n",
    "    def step(self, action):\n",
    "        agent = self.agent_selection\n",
    "       \n",
    "        if agent == 'robber':\n",
    "            current_row, current_col = self.state\n",
    "            next_state = list(self.state)\n",
    "           \n",
    "            if action == 0:  # Move right\n",
    "                if current_col + 1 < self.maze.shape[1] and self.maze[current_row, current_col + 1] == 0:\n",
    "                    next_state[1] += 1\n",
    "            elif action == 1:  # Move down\n",
    "                if current_row + 1 < self.maze.shape[0] and self.maze[current_row + 1, current_col] == 0:\n",
    "                    next_state[0] += 1\n",
    "            elif action == 2:  # Move up\n",
    "                if current_row - 1 >= 0 and self.maze[current_row - 1, current_col] == 0:\n",
    "                    next_state[0] -= 1\n",
    "            elif action == 3:  # Move left\n",
    "                if current_col - 1 >= 0 and self.maze[current_row, current_col - 1] == 0:\n",
    "                    next_state[1] -= 1\n",
    "           \n",
    "            self.rewards[agent] = -1  # Each step costs -1\n",
    "            if next_state != list(self.state):\n",
    "                self.state = tuple(next_state)\n",
    "                if self.state in self.checkpoints:\n",
    "                    self.rewards[agent] += 30  # Checkpoint reached\n",
    "                if self.state == self.goal:\n",
    "                    self.rewards[agent] += 100  # Goal reached\n",
    "                    self.dones = {agent: True for agent in self.agents}\n",
    "            else:\n",
    "                self.dones[agent] = False\n",
    "\n",
    "        elif agent == 'cop':\n",
    "            cop_action = self.cop_move()\n",
    "            self.cop_step(cop_action)\n",
    "            self.rewards[agent] = -1  # Each step costs -1\n",
    "       \n",
    "        # Check if cop catches the robber\n",
    "        if self.cop_state == self.state:\n",
    "            self.dones = {agent: True for agent in self.agents}\n",
    "            self.rewards['robber'] -= 100  # Negative reward if cop catches the robber\n",
    "       \n",
    "        self.agent_selection = self._agent_selector.next()\n",
    "        self._accumulate_rewards()\n",
    "\n",
    "    def cop_move(self):\n",
    "        cop_row, cop_col = self.cop_state\n",
    "        agent_row, agent_col = self.state\n",
    "       \n",
    "        if cop_row < agent_row and self.maze[cop_row + 1, cop_col] == 0:\n",
    "            return 1  # Move down\n",
    "        elif cop_row > agent_row and self.maze[cop_row - 1, cop_col] == 0:\n",
    "            return 2  # Move up\n",
    "        elif cop_col < agent_col and self.maze[cop_row, cop_col + 1] == 0:\n",
    "            return 0  # Move right\n",
    "        elif cop_col > agent_col and self.maze[cop_row, cop_col - 1] == 0:\n",
    "            return 3  # Move left\n",
    "        return np.random.choice([0, 1, 2, 3])  # Random move if blocked\n",
    "   \n",
    "    def cop_step(self, action):\n",
    "        cop_row, cop_col = self.cop_state\n",
    "        next_cop_state = list(self.cop_state)\n",
    "       \n",
    "        if action == 0: # Move right\n",
    "            if cop_col + 1 < self.maze.shape[1] and self.maze[cop_row, cop_col + 1] == 0:\n",
    "                next_cop_state[1] += 1\n",
    "        elif action == 1:  # Move down\n",
    "            if cop_row + 1 < self.maze.shape[0] and self.maze[cop_row + 1, cop_col] == 0:\n",
    "                next_cop_state[0] += 1\n",
    "        elif action == 2:  # Move up\n",
    "            if cop_row - 1 >= 0 and self.maze[cop_row - 1, cop_col] == 0:\n",
    "                next_cop_state[0] -= 1\n",
    "        elif action == 3:  # Move left\n",
    "            if cop_col - 1 >= 0 and self.maze[cop_row, cop_col - 1] == 0:\n",
    "                next_cop_state[1] -= 1\n",
    "       \n",
    "        self.cop_state = tuple(next_cop_state)\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        self.screen.fill((255, 255, 255)) # White background\n",
    "\n",
    "        # Draw the maze\n",
    "        for row in range(self.maze.shape[0]):\n",
    "            for col in range(self.maze.shape[1]):\n",
    "                color = (255, 255, 255) # white color for paths\n",
    "                if self.maze[row, col] == 1:\n",
    "                    color = (0, 0, 0) # black color for Walls\n",
    "                pygame.draw.rect(self.screen, color,\n",
    "                                 pygame.Rect(col * self.cell_size, row * self.cell_size, self.cell_size, self.cell_size))\n",
    "\n",
    "        # Draw the start position as green color\n",
    "        pygame.draw.rect(self.screen, (0, 255, 0),\n",
    "                         pygame.Rect(self.start[1] * self.cell_size, self.start[0] * self.cell_size, self.cell_size, self.cell_size))\n",
    "\n",
    "        # Draw the goal position as red color\n",
    "        pygame.draw.rect(self.screen, (255, 0, 0),\n",
    "                         pygame.Rect(self.goal[1] * self.cell_size, self.goal[0] * self.cell_size, self.cell_size, self.cell_size))\n",
    "\n",
    "        # Draw checkpoints as blue color\n",
    "        for cp in self.checkpoints:\n",
    "            pygame.draw.rect(self.screen, (0, 0, 255),\n",
    "                             pygame.Rect(cp[1] * self.cell_size, cp[0] * self.cell_size, self.cell_size, self.cell_size))\n",
    "\n",
    "        # Draw the robber as a yellow colored square\n",
    "        pygame.draw.rect(self.screen, (255, 255, 0),\n",
    "                         pygame.Rect(self.state[1] * self.cell_size, self.state[0] * self.cell_size, self.cell_size, self.cell_size))\n",
    "\n",
    "        # Draw the cop as an orange colored square\n",
    "        pygame.draw.rect(self.screen, (255, 165, 0),\n",
    "                         pygame.Rect(self.cop_state[1] * self.cell_size, self.cop_state[0] * self.cell_size, self.cell_size, self.cell_size))\n",
    "\n",
    "        pygame.display.flip()\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    def close(self):\n",
    "        pygame.quit()\n",
    "\n",
    "    def check_event(self):\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                self.close()\n",
    "                exit()\n",
    "\n",
    "# Wrapping the environment\n",
    "def env():\n",
    "    env = MazeXEnv()\n",
    "    env = wrappers.CaptureStdoutWrapper(env)\n",
    "    return env\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b87565-25a9-44e6-9850-b476259ee049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the neural networks for PPO with separate actor and critic networks\n",
    "class ActorNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, output_dim)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.softmax(self.fc4(x), dim=-1)\n",
    "        return x\n",
    "        \n",
    "class CriticNetwork(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(CriticNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c5f4e6b-04ad-41f8-863f-d84af5f7ad26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_21024\\1810912911.py:34: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  states = torch.FloatTensor(self.states)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 - Total Reward Robber: -1072, Total Reward Cop: -971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 - Total Reward Robber: -1054, Total Reward Cop: -1054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2 - Total Reward Robber: -3383, Total Reward Cop: -3282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3 - Total Reward Robber: -1597, Total Reward Cop: -1597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4 - Total Reward Robber: -509, Total Reward Cop: -509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5 - Total Reward Robber: -969, Total Reward Cop: -969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6 - Total Reward Robber: -208, Total Reward Cop: -208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7 - Total Reward Robber: -1513, Total Reward Cop: -1412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 8 - Total Reward Robber: -1765, Total Reward Cop: -2974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 9 - Total Reward Robber: -1647, Total Reward Cop: -1647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10 - Total Reward Robber: -725, Total Reward Cop: -824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 11 - Total Reward Robber: -2356, Total Reward Cop: -2255\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "display Surface quit",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 162\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    161\u001b[0m     env_instance \u001b[38;5;241m=\u001b[39m env()\n\u001b[1;32m--> 162\u001b[0m     agent_robber, agent_cop, rewards_robber, rewards_cop \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ppo\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_instance\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 133\u001b[0m, in \u001b[0;36mtrain_ppo\u001b[1;34m(env, num_episodes, update_interval)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m    131\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m     env\u001b[38;5;241m.\u001b[39mcheck_event()\n\u001b[0;32m    136\u001b[0m rewards_robber\u001b[38;5;241m.\u001b[39mappend(total_reward_robber)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pettingzoo\\utils\\wrappers\\capture_stdout.py:23\u001b[0m, in \u001b[0;36mCaptureStdoutWrapper.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m capture_stdout() \u001b[38;5;28;01mas\u001b[39;00m stdout:\n\u001b[1;32m---> 23\u001b[0m         \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m         val \u001b[38;5;241m=\u001b[39m stdout\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m val\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pettingzoo\\utils\\wrappers\\base.py:35\u001b[0m, in \u001b[0;36mBaseWrapper.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 145\u001b[0m, in \u001b[0;36mMazeXEnv.render\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 145\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscreen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# White background\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;66;03m# Draw the maze\u001b[39;00m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaze\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n",
      "\u001b[1;31merror\u001b[0m: display Surface quit"
     ]
    }
   ],
   "source": [
    "class PPOAgent:\n",
    "    def __init__(self, env, input_dim, action_dim, lr=3e-4, gamma=0.99, clip_ratio=0.2, update_interval=2000):\n",
    "        self.env = env\n",
    "        self.gamma = gamma\n",
    "        self.clip_ratio = clip_ratio\n",
    "        self.update_interval = update_interval\n",
    "\n",
    "        self.actor = ActorNetwork(input_dim, action_dim)\n",
    "        self.critic = CriticNetwork(input_dim)\n",
    "        self.optimizer_actor = optim.Adam(self.actor.parameters(), lr=lr)\n",
    "        self.optimizer_critic = optim.Adam(self.critic.parameters(), lr=lr)\n",
    "\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.log_probs = []\n",
    "\n",
    "    def get_action(self, state):\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            action_logits = self.actor(state)\n",
    "        action_prob = torch.softmax(action_logits, dim=-1)\n",
    "        action = torch.multinomial(action_prob, 1).item()\n",
    "        log_prob = torch.log(action_prob.squeeze(0)[action])\n",
    "        return action, log_prob\n",
    "\n",
    "    def store_transition(self, state, action, reward, log_prob):\n",
    "        self.states.append(state)\n",
    "        self.actions.append(action)\n",
    "        self.rewards.append(reward)\n",
    "        self.log_probs.append(log_prob)\n",
    "\n",
    "    def update(self):\n",
    "        states = torch.FloatTensor(self.states)\n",
    "        actions = torch.LongTensor(self.actions)\n",
    "        rewards = torch.FloatTensor(self.rewards)\n",
    "        log_probs = torch.FloatTensor(self.log_probs)\n",
    "\n",
    "        old_values = self.critic(states).squeeze()\n",
    "        returns = self.compute_returns(rewards)\n",
    "\n",
    "        advantages = returns - old_values.detach()\n",
    "\n",
    "        for _ in range(10):  # PPO updates\n",
    "            new_log_probs, values = self.evaluate_actions(states, actions)\n",
    "            values = values.squeeze()\n",
    "            ratios = torch.exp(new_log_probs - log_probs)\n",
    "\n",
    "            surr1 = ratios * advantages\n",
    "            surr2 = torch.clamp(ratios, 1 - self.clip_ratio, 1 + self.clip_ratio) * advantages\n",
    "            policy_loss = -torch.min(surr1, surr2).mean()\n",
    "\n",
    "            value_loss = (returns - values).pow(2).mean()\n",
    "\n",
    "            self.optimizer_actor.zero_grad()\n",
    "            self.optimizer_critic.zero_grad()\n",
    "            policy_loss.backward()\n",
    "            value_loss.backward()\n",
    "            self.optimizer_actor.step()\n",
    "            self.optimizer_critic.step()\n",
    "\n",
    "        self.states, self.actions, self.rewards, self.log_probs = [], [], [], []\n",
    "\n",
    "    def compute_returns(self, rewards):\n",
    "        returns = []\n",
    "        R = 0\n",
    "        for r in reversed(rewards):\n",
    "            R = r + self.gamma * R\n",
    "            returns.insert(0, R)\n",
    "        returns = torch.FloatTensor(returns)\n",
    "        return returns\n",
    "\n",
    "    def evaluate_actions(self, states, actions):\n",
    "        action_logits = self.actor(states)\n",
    "        values = self.critic(states)\n",
    "        action_probs = torch.softmax(action_logits, dim=-1)\n",
    "        action_log_probs = torch.log(action_probs.gather(1, actions.unsqueeze(1)).squeeze())\n",
    "        return action_log_probs, values\n",
    "\n",
    "def train_ppo(env, num_episodes=1000, update_interval=2000):\n",
    "    input_dim_robber = env.observation_spaces['robber'].shape[0]\n",
    "    action_dim_robber = env.action_spaces['robber'].n\n",
    "    input_dim_cop = env.observation_spaces['cop'].shape[0]\n",
    "    action_dim_cop = env.action_spaces['cop'].n\n",
    "\n",
    "    agent_robber = PPOAgent(env, input_dim_robber, action_dim_robber)\n",
    "    agent_cop = PPOAgent(env, input_dim_cop, action_dim_cop)\n",
    "\n",
    "    rewards_robber = []\n",
    "    rewards_cop = []\n",
    "\n",
    "    plt.ion()  # Turn on interactive mode\n",
    "    fig, ax = plt.subplots()\n",
    "    line1, = ax.plot(rewards_robber, label='Robber')\n",
    "    line2, = ax.plot(rewards_cop, label='Cop')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Total Reward')\n",
    "    plt.legend()\n",
    "    plt.title('Cumulative Rewards vs Episodes')\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        env.reset()\n",
    "        total_reward_robber = 0\n",
    "        total_reward_cop = 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            for agent in env.agent_order:\n",
    "                state = env.observe(agent)\n",
    "                if agent == 'robber':\n",
    "                    action, log_prob = agent_robber.get_action(state)\n",
    "                    env.step(action)\n",
    "                    next_state = env.observe(agent)\n",
    "                    reward = env.rewards[agent]\n",
    "                    done = env.dones[agent]\n",
    "\n",
    "                    agent_robber.store_transition(state, action, reward, log_prob)\n",
    "                    total_reward_robber += reward\n",
    "\n",
    "                elif agent == 'cop':\n",
    "                    action, log_prob = agent_cop.get_action(state)\n",
    "                    env.step(action)\n",
    "                    next_state = env.observe(agent)\n",
    "                    reward = env.rewards[agent]\n",
    "                    done = env.dones[agent]\n",
    "\n",
    "                    agent_cop.store_transition(state, action, reward, log_prob)\n",
    "                    total_reward_cop += reward\n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            env.render()\n",
    "            env.check_event()\n",
    "\n",
    "        rewards_robber.append(total_reward_robber)\n",
    "        rewards_cop.append(total_reward_cop)\n",
    "\n",
    "        # Update the plot\n",
    "        line1.set_ydata(rewards_robber)\n",
    "        line1.set_xdata(range(len(rewards_robber)))\n",
    "        line2.set_ydata(rewards_cop)\n",
    "        line2.set_xdata(range(len(rewards_cop)))\n",
    "        ax.relim()\n",
    "        ax.autoscale_view()\n",
    "        plt.draw()\n",
    "        plt.pause(0.01)\n",
    "\n",
    "        if episode % agent_robber.update_interval == 0:\n",
    "            agent_robber.update()\n",
    "            agent_cop.update()\n",
    "\n",
    "        print(f\"Episode {episode} - Total Reward Robber: {total_reward_robber}, Total Reward Cop: {total_reward_cop}\")\n",
    "\n",
    "    plt.ioff()  # Turn off interactive mode\n",
    "    plt.show()\n",
    "\n",
    "    return agent_robber, agent_cop, rewards_robber, rewards_cop\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env_instance = env()\n",
    "    agent_robber, agent_cop, rewards_robber, rewards_cop = train_ppo(env_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c9223b-4288-4008-878d-967e8b9d5c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
